# -----------------------------------------------------------------------
#
#  Tokiwa Software GmbH, Germany
#
#  Source code of Fuzion webserver feature Feeds
#
# -----------------------------------------------------------------------

# Feeds feature to periodically update rss-feeds
# and store the results in fields
#
module Feeds ref is

  # the update interval for the feeds
  #
  update_interval := time.duration.minutes 15

  module github   := concur.atomic (Sequence rss_feed_entry) .new []

  module mastodon := concur.atomic (Sequence rss_feed_entry) .new []


  # init background thread to periodically update
  # the rss feeds
  #
  module init =>
    _ := concur.threads.spawn ()->
      do
        fuzion.runtime.fault
          .try ()->
            get_github
          .catch  e->
            logger.log "contract_fault (github feed): $e"

        fuzion.runtime.fault
          .try ()->
            get_mastodon
          .catch  e->
            logger.log "contract_fault (mastodon feed): $e"

        time.nano.sleep update_interval


  # download, parse and store the github rss-feed
  #
  # NYI: CLEANUP: ugly code, we need some better api for xml_nodes
  #
  module get_github =>

    # parse and save github commits using the graphql api
    #
    commits Sequence rss_feed_entry =>
      token := util.read_file_as_string (path.of "./github-graphql-token.txt")
                   .or_else ""
                   .trim

      request_header := container.ordered_map String String
        .empty
        .add "Content-Type" "application/json"
        .add "User-Agent" "fzweb (+https://github.com/tokiwa-software/fzweb)"
        .add "Authorization" "Bearer {token}"

      github_graphql_endpoint := "https://api.github.com/graphql"

      graphql_query := """
        \{
          "query": "query \{ \
            repository(owner: \\"tokiwa-software\\", name: \\"fuzion\\") \{ \
              ref(qualifiedName: \\"main\\") \{ \
                target \{ \
                  ... on Commit \{ \
                    history(first: 10) \{ \
                      edges \{ \
                        node \{ \
                          message committedDate url \
                        } \
                      } \
                    } \
                  } \
                } \
              } \
            } \
          }"
        }"""

      if !token.is_empty
        graphql_request := web.post4 github_graphql_endpoint graphql_query.utf8 request_header

        match nom.parsers.json.call graphql_request.get
          error => Sequence rss_feed_entry .empty
          ns nom.success =>
            ns.out.access [ "data", "repository", "ref", "target", "history", "edges" ]
              .bind es->
                match es
                  edges Sequence =>
                    edges.map rss_feed_entry edge->
                      edge
                        .access [ "node" ]
                        .bind n->
                          title :=
                            n.access [ "message" ]
                             .bind msg->
                               match msg
                                 msg_s String => msg_s.split "\n" .first.or_else "no title found"
                                 * => ""
                             .as_string

                          url :=
                            n.access [ "url" ]
                             .bind u->
                               match u
                                 u2 String => u2
                                 * => ""
                             .as_string

                          committed_date :=
                            n.access [ "committedDate" ]
                             .bind date->
                               match date
                                 d String => d.substring 0 10
                                 * => "1970-01-01"
                             .as_string

                          rss_feed_entry title url committed_date
                        .or_else (rss_feed_entry "error while parsing" "https://fuzion-lang.dev" "1970-01-01")
                  * => Sequence rss_feed_entry .empty
              .or_else (Sequence rss_feed_entry).empty
      else
        Sequence rss_feed_entry .empty


    github.write commits.as_array


  # download, parse and store the mastodon rss-feed
  #
  # NYI: CLEANUP: ugly code, we need some better api for xml_nodes
  #
  module get_mastodon =>

    #
    # feed: looks like this
    #
    # rss
    #   channel
    #     item
    #       link
    #       pubDate
    #       description
    #


    extract_nodes(n Sequence (choice nom.parsers.xml_node String)) Sequence nom.parsers.xml_node =>
      n.flat_map x->
        match x
          String => []
          xn nom.parsers.xml_node => [xn]


    stringify(c choice nom.parsers.xml_node String) =>
      match c
        str String => str
        xn nom.parsers.xml_node => xn.as_string


    mastodon_xml =>
      nom.parsers.xml
        .call (web.get4 "https://types.pl/@fuzion.rss" .val)
        .val.out


    m_feed := extract_nodes (mastodon_xml[0].data)
      .flat_map xn->
        extract_nodes xn.data
      .flat_map xn->
        if xn.name = "item" then
          res := extract_nodes xn.data
            .reduce (rss_feed_entry "" "" "") (r,t)->
              if t.name = "description"
                rss_feed_entry (stringify t.data[0]) r.href r.updated
              else if t.name = "link"
                rss_feed_entry r.title (stringify t.data[0]) r.updated
              else if t.name = "pubDate"
                rss_feed_entry r.title r.href (stringify t.data[0])
              else
                r
          [res]
        else
          []
      .as_array

    mastodon.write m_feed
